#!/usr/bin/env python3
"""
AgentBus é›†æˆæµ‹è¯•è¿è¡Œè„šæœ¬

æ­¤è„šæœ¬ç”¨äºè¿è¡Œå®Œæ•´çš„AgentBusç³»ç»Ÿé›†æˆæµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
- å®Œæ•´çš„ç³»ç»Ÿé›†æˆæµ‹è¯•
- æ’ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•
- CLIé›†æˆæµ‹è¯•
- è‡ªå®šä¹‰æµ‹è¯•å¥—ä»¶

æ”¯æŒçš„åŠŸèƒ½ï¼š
- è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•
- è¿è¡Œç‰¹å®šæµ‹è¯•ç±»æˆ–æµ‹è¯•æ–¹æ³•
- å¹¶è¡Œæµ‹è¯•æ‰§è¡Œ
- æµ‹è¯•ç»“æœæŠ¥å‘Šç”Ÿæˆ
- æµ‹è¯•è¦†ç›–ç‡åˆ†æ
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- é”™è¯¯è¯Šæ–­å’ŒæŠ¥å‘Š
"""

import sys
import os
import argparse
import json
import time
import logging
import subprocess
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æµ‹è¯•é…ç½®
try:
    from tests.conftest import pytest_plugins
    from tests.test_integration.test_complete_system import TestCompleteSystemIntegration
    from tests.test_integration.test_plugin_integration import TestPluginSystemIntegration
    from tests.test_integration.test_cli_integration import TestCLIIntegration
except ImportError as e:
    print(f"âŒ å¯¼å…¥æµ‹è¯•æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æµ‹è¯•æ–‡ä»¶è·¯å¾„æ­£ç¡®")
    sys.exit(1)


class IntegrationTestRunner:
    """é›†æˆæµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._load_default_config()
        self.setup_logging()
        self.test_results = []
        self.start_time = None
        self.end_time = None
        
    def _load_default_config(self) -> Dict[str, Any]:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            "test_suites": {
                "complete_system": {
                    "enabled": True,
                    "description": "å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•",
                    "timeout": 300,  # 5åˆ†é’Ÿ
                    "parallel": False
                },
                "plugin_system": {
                    "enabled": True,
                    "description": "æ’ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•",
                    "timeout": 180,  # 3åˆ†é’Ÿ
                    "parallel": True
                },
                "cli_integration": {
                    "enabled": True,
                    "description": "CLIé›†æˆæµ‹è¯•",
                    "timeout": 120,  # 2åˆ†é’Ÿ
                    "parallel": True
                }
            },
            "execution": {
                "parallel": True,
                "max_workers": 4,
                "timeout": 600,  # 10åˆ†é’Ÿæ€»è¶…æ—¶
                "retry_failed": True,
                "max_retries": 2
            },
            "reporting": {
                "format": "html",  # html, json, xml, text
                "output_dir": "test_reports",
                "include_coverage": True,
                "include_performance": True
            },
            "environment": {
                "test_data_dir": "test_data",
                "temp_dir": "test_temp",
                "log_level": "INFO",
                "cleanup": True
            }
        }
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        log_level = self.config["environment"]["log_level"]
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler('integration_tests.log', mode='w')
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _prepare_test_environment(self) -> str:
        """å‡†å¤‡æµ‹è¯•ç¯å¢ƒ"""
        self.logger.info("ğŸ”§ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = self.config["environment"]["temp_dir"]
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir, exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
        test_data_dir = self.config["environment"]["test_data_dir"]
        if not os.path.exists(test_data_dir):
            os.makedirs(test_data_dir, exist_ok=True)
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_dir = self.config["reporting"]["output_dir"]
        if not os.path.exists(report_dir):
            os.makedirs(report_dir, exist_ok=True)
        
        self.logger.info(f"âœ… æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆ (temp_dir: {temp_dir})")
        return temp_dir
    
    def _cleanup_test_environment(self, temp_dir: str):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.config["environment"]["cleanup"]:
            self.logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
            try:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                self.logger.info("âœ… æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ¸…ç†æµ‹è¯•ç¯å¢ƒæ—¶å‡ºç°è­¦å‘Š: {e}")
    
    def run_complete_system_tests(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•...")
        
        test_name = "å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•"
        start_time = time.time()
        
        try:
            # ä½¿ç”¨pytestè¿è¡Œå®Œæ•´ç³»ç»Ÿæµ‹è¯•
            test_file = project_root / "tests/test_integration/test_complete_system.py"
            cmd = [
                "python", "-m", "pytest",
                str(test_file),
                "-v",
                "--tb=short",
                "--timeout=300",
                f"--junit-xml={self.config['reporting']['output_dir']}/complete_system_report.xml"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            
            end_time = time.time()
            duration = end_time - start_time
            
            success = result.returncode == 0
            
            test_result = {
                "test_name": test_name,
                "success": success,
                "duration": duration,
                "start_time": datetime.fromtimestamp(start_time).isoformat(),
                "end_time": datetime.fromtimestamp(end_time).isoformat(),
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "command": " ".join(cmd)
            }
            
            if success:
                self.logger.info(f"âœ… {test_name} å®Œæˆ (è€—æ—¶: {duration:.2f}s)")
            else:
                self.logger.error(f"âŒ {test_name} å¤±è´¥ (è€—æ—¶: {duration:.2f}s)")
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ {test_name} æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {
                "test_name": test_name,
                "success": False,
                "duration": time.time() - start_time,
                "error": str(e),
                "exception": True
            }
    
    def run_plugin_system_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ’ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•"""
        self.logger.info("ğŸ”Œ å¼€å§‹è¿è¡Œæ’ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•...")
        
        test_name = "æ’ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•"
        start_time = time.time()
        
        try:
            # ä½¿ç”¨pytestè¿è¡Œæ’ä»¶ç³»ç»Ÿæµ‹è¯•
            test_file = project_root / "tests/test_integration/test_plugin_integration.py"
            cmd = [
                "python", "-m", "pytest",
                str(test_file),
                "-v",
                "--tb=short",
                "--timeout=180",
                f"--junit-xml={self.config['reporting']['output_dir']}/plugin_system_report.xml"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            
            end_time = time.time()
            duration = end_time - start_time
            
            success = result.returncode == 0
            
            test_result = {
                "test_name": test_name,
                "success": success,
                "duration": duration,
                "start_time": datetime.fromtimestamp(start_time).isoformat(),
                "end_time": datetime.fromtimestamp(end_time).isoformat(),
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "command": " ".join(cmd)
            }
            
            if success:
                self.logger.info(f"âœ… {test_name} å®Œæˆ (è€—æ—¶: {duration:.2f}s)")
            else:
                self.logger.error(f"âŒ {test_name} å¤±è´¥ (è€—æ—¶: {duration:.2f}s)")
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ {test_name} æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {
                "test_name": test_name,
                "success": False,
                "duration": time.time() - start_time,
                "error": str(e),
                "exception": True
            }
    
    def run_cli_integration_tests(self) -> Dict[str, Any]:
        """è¿è¡ŒCLIé›†æˆæµ‹è¯•"""
        self.logger.info("ğŸ’» å¼€å§‹è¿è¡ŒCLIé›†æˆæµ‹è¯•...")
        
        test_name = "CLIé›†æˆæµ‹è¯•"
        start_time = time.time()
        
        try:
            # ä½¿ç”¨pytestè¿è¡ŒCLIé›†æˆæµ‹è¯•
            test_file = project_root / "tests/test_integration/test_cli_integration.py"
            cmd = [
                "python", "-m", "pytest",
                str(test_file),
                "-v",
                "--tb=short",
                "--timeout=120",
                f"--junit-xml={self.config['reporting']['output_dir']}/cli_integration_report.xml"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            
            end_time = time.time()
            duration = end_time - start_time
            
            success = result.returncode == 0
            
            test_result = {
                "test_name": test_name,
                "success": success,
                "duration": duration,
                "start_time": datetime.fromtimestamp(start_time).isoformat(),
                "end_time": datetime.fromtimestamp(end_time).isoformat(),
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "command": " ".join(cmd)
            }
            
            if success:
                self.logger.info(f"âœ… {test_name} å®Œæˆ (è€—æ—¶: {duration:.2f}s)")
            else:
                self.logger.error(f"âŒ {test_name} å¤±è´¥ (è€—æ—¶: {duration:.2f}s)")
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ {test_name} æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {
                "test_name": test_name,
                "success": False,
                "duration": time.time() - start_time,
                "error": str(e),
                "exception": True
            }
    
    def run_specific_tests(self, test_patterns: List[str]) -> Dict[str, Any]:
        """è¿è¡ŒæŒ‡å®šçš„æµ‹è¯•"""
        self.logger.info(f"ğŸ¯ å¼€å§‹è¿è¡ŒæŒ‡å®šæµ‹è¯•: {', '.join(test_patterns)}")
        
        test_name = f"æŒ‡å®šæµ‹è¯• ({', '.join(test_patterns)})"
        start_time = time.time()
        
        try:
            cmd = [
                "python", "-m", "pytest",
                "-v",
                "--tb=short",
                "--timeout=300",
                f"--junit-xml={self.config['reporting']['output_dir']}/specific_tests_report.xml"
            ]
            
            # æ·»åŠ æµ‹è¯•æ¨¡å¼
            for pattern in test_patterns:
                cmd.append(pattern)
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            
            end_time = time.time()
            duration = end_time - start_time
            
            success = result.returncode == 0
            
            test_result = {
                "test_name": test_name,
                "success": success,
                "duration": duration,
                "start_time": datetime.fromtimestamp(start_time).isoformat(),
                "end_time": datetime.fromtimestamp(end_time).isoformat(),
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "command": " ".join(cmd),
                "test_patterns": test_patterns
            }
            
            if success:
                self.logger.info(f"âœ… {test_name} å®Œæˆ (è€—æ—¶: {duration:.2f}s)")
            else:
                self.logger.error(f"âŒ {test_name} å¤±è´¥ (è€—æ—¶: {duration:.2f}s)")
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ {test_name} æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {
                "test_name": test_name,
                "success": False,
                "duration": time.time() - start_time,
                "error": str(e),
                "exception": True,
                "test_patterns": test_patterns
            }
    
    def generate_test_report(self, results: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        self.logger.info("ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        report_dir = self.config["reporting"]["output_dir"]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_report = {
            "test_run": {
                "timestamp": timestamp,
                "total_tests": len(results),
                "successful_tests": sum(1 for r in results if r.get("success", False)),
                "failed_tests": sum(1 for r in results if not r.get("success", True)),
                "total_duration": sum(r.get("duration", 0) for r in results),
                "start_time": results[0].get("start_time") if results else None,
                "end_time": results[-1].get("end_time") if results else None
            },
            "results": results,
            "configuration": self.config
        }
        
        json_file = os.path.join(report_dir, f"integration_test_report_{timestamp}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        text_summary = self._generate_text_summary(results)
        text_file = os.path.join(report_dir, f"integration_test_summary_{timestamp}.txt")
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write(text_summary)
        
        self.logger.info(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ:")
        self.logger.info(f"   JSON: {json_file}")
        self.logger.info(f"   æ–‡æœ¬: {text_file}")
        
        return json_file
    
    def _generate_text_summary(self, results: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼æ‘˜è¦"""
        successful_tests = sum(1 for r in results if r.get("success", False))
        failed_tests = len(results) - successful_tests
        total_duration = sum(r.get("duration", 0) for r in results)
        
        summary = f"""
AgentBus é›†æˆæµ‹è¯•æŠ¥å‘Š
{'=' * 50}

æµ‹è¯•æ¦‚è§ˆ:
- æ€»æµ‹è¯•æ•°: {len(results)}
- é€šè¿‡æµ‹è¯•: {successful_tests}
- å¤±è´¥æµ‹è¯•: {failed_tests}
- æ€»è€—æ—¶: {total_duration:.2f}ç§’
- æˆåŠŸç‡: {(successful_tests/len(results)*100):.1f}%

è¯¦ç»†ç»“æœ:
"""
        
        for result in results:
            status = "PASS" if result.get("success", False) else "FAIL"
            duration = result.get("duration", 0)
            summary += f"\n[{status}] {result.get('test_name', 'Unknown Test')} ({duration:.2f}s)"
            
            if not result.get("success", False):
                if result.get("stderr"):
                    summary += f"\n  é”™è¯¯: {result['stderr'][:200]}..."
                if result.get("exception"):
                    summary += f"\n  å¼‚å¸¸: {result.get('error', 'Unknown error')}"
        
        summary += f"\n\næµ‹è¯•å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        return summary
    
    def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•...")
        
        self.start_time = time.time()
        temp_dir = self._prepare_test_environment()
        
        try:
            all_results = []
            overall_success = True
            
            # è¿è¡Œå®Œæ•´ç³»ç»Ÿæµ‹è¯•
            if self.config["test_suites"]["complete_system"]["enabled"]:
                result = self.run_complete_system_tests()
                all_results.append(result)
                if not result.get("success", False):
                    overall_success = False
            
            # è¿è¡Œæ’ä»¶ç³»ç»Ÿæµ‹è¯•
            if self.config["test_suites"]["plugin_system"]["enabled"]:
                result = self.run_plugin_system_tests()
                all_results.append(result)
                if not result.get("success", False):
                    overall_success = False
            
            # è¿è¡ŒCLIé›†æˆæµ‹è¯•
            if self.config["test_suites"]["cli_integration"]["enabled"]:
                result = self.run_cli_integration_tests()
                all_results.append(result)
                if not result.get("success", False):
                    overall_success = False
            
            self.test_results = all_results
            self.end_time = time.time()
            
            # ç”ŸæˆæŠ¥å‘Š
            report_file = self.generate_test_report(all_results)
            
            # è¾“å‡ºæ‘˜è¦
            self._print_summary(all_results)
            
            return overall_success
            
        finally:
            self._cleanup_test_environment(temp_dir)
    
    def run_specific_test_suite(self, suite_name: str) -> bool:
        """è¿è¡Œç‰¹å®šçš„æµ‹è¯•å¥—ä»¶"""
        self.logger.info(f"ğŸ¯ è¿è¡Œç‰¹å®šæµ‹è¯•å¥—ä»¶: {suite_name}")
        
        self.start_time = time.time()
        temp_dir = self._prepare_test_environment()
        
        try:
            result = None
            
            if suite_name == "complete_system":
                result = self.run_complete_system_tests()
            elif suite_name == "plugin_system":
                result = self.run_plugin_system_tests()
            elif suite_name == "cli_integration":
                result = self.run_cli_integration_tests()
            else:
                self.logger.error(f"âŒ æœªçŸ¥çš„æµ‹è¯•å¥—ä»¶: {suite_name}")
                return False
            
            if result:
                self.test_results = [result]
                self.end_time = time.time()
                
                # ç”ŸæˆæŠ¥å‘Š
                report_file = self.generate_test_report([result])
                
                # è¾“å‡ºæ‘˜è¦
                self._print_summary([result])
                
                return result.get("success", False)
            
            return False
            
        finally:
            self._cleanup_test_environment(temp_dir)
    
    def run_custom_tests(self, test_patterns: List[str]) -> bool:
        """è¿è¡Œè‡ªå®šä¹‰æµ‹è¯•"""
        self.logger.info(f"ğŸ¨ è¿è¡Œè‡ªå®šä¹‰æµ‹è¯•: {', '.join(test_patterns)}")
        
        self.start_time = time.time()
        temp_dir = self._prepare_test_environment()
        
        try:
            result = self.run_specific_tests(test_patterns)
            self.test_results = [result]
            self.end_time = time.time()
            
            # ç”ŸæˆæŠ¥å‘Š
            report_file = self.generate_test_report([result])
            
            # è¾“å‡ºæ‘˜è¦
            self._print_summary([result])
            
            return result.get("success", False)
            
        finally:
            self._cleanup_test_environment(temp_dir)
    
    def _print_summary(self, results: List[Dict[str, Any]]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        successful_tests = sum(1 for r in results if r.get("success", False))
        failed_tests = len(results) - successful_tests
        total_duration = sum(r.get("duration", 0) for r in results)
        
        print("\n" + "=" * 60)
        print("ğŸ¯ AgentBus é›†æˆæµ‹è¯•æ‘˜è¦")
        print("=" * 60)
        print(f"ğŸ“Š æ€»æµ‹è¯•æ•°: {len(results)}")
        print(f"âœ… é€šè¿‡æµ‹è¯•: {successful_tests}")
        print(f"âŒ å¤±è´¥æµ‹è¯•: {failed_tests}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {(successful_tests/len(results)*100):.1f}%")
        
        if self.start_time and self.end_time:
            print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(self.start_time).strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"ğŸ•’ ç»“æŸæ—¶é—´: {datetime.fromtimestamp(self.end_time).strftime('%Y-%m-%d %H:%M:%S')}")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for result in results:
            status_icon = "âœ…" if result.get("success", False) else "âŒ"
            duration = result.get("duration", 0)
            print(f"  {status_icon} {result.get('test_name', 'Unknown Test')} ({duration:.2f}s)")
        
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="AgentBus é›†æˆæµ‹è¯•è¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python run_integration_tests.py --all                    # è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•
  python run_integration_tests.py --suite complete_system  # è¿è¡Œå®Œæ•´ç³»ç»Ÿæµ‹è¯•
  python run_integration_tests.py --pattern tests/test_integration/test_complete_system.py::TestCompleteSystemIntegration::test_plugin_system_integration
  python run_integration_tests.py --list                   # åˆ—å‡ºå¯ç”¨çš„æµ‹è¯•å¥—ä»¶
        """
    )
    
    parser.add_argument(
        "--all",
        action="store_true",
        help="è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"
    )
    
    parser.add_argument(
        "--suite",
        choices=["complete_system", "plugin_system", "cli_integration"],
        help="è¿è¡Œç‰¹å®šçš„æµ‹è¯•å¥—ä»¶"
    )
    
    parser.add_argument(
        "--pattern",
        action="append",
        help="è¿è¡ŒåŒ¹é…æ¨¡å¼çš„ç‰¹å®šæµ‹è¯• (å¯å¤šæ¬¡ä½¿ç”¨)"
    )
    
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºå¯ç”¨çš„æµ‹è¯•å¥—ä»¶"
    )
    
    parser.add_argument(
        "--config",
        help="è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="å¯ç”¨å¹¶è¡Œæµ‹è¯•æ‰§è¡Œ"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="è¯¦ç»†è¾“å‡º"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = None
    if args.config:
        try:
            with open(args.config, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = IntegrationTestRunner(config)
    
    # è®¾ç½®è¯¦ç»†è¾“å‡º
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # è®¾ç½®å¹¶è¡Œæ‰§è¡Œ
    if args.parallel:
        runner.config["execution"]["parallel"] = True
    
    # å¤„ç†å‘½ä»¤
    if args.list:
        print("ğŸ“‹ å¯ç”¨çš„æµ‹è¯•å¥—ä»¶:")
        print("  complete_system  - å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•")
        print("  plugin_system   - æ’ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•")
        print("  cli_integration - CLIé›†æˆæµ‹è¯•")
        print("\nå¯ç”¨çš„æµ‹è¯•æ¨¡å¼ç¤ºä¾‹:")
        print("  tests/test_integration/test_complete_system.py")
        print("  tests/test_integration/test_complete_system.py::TestCompleteSystemIntegration")
        print("  tests/test_integration/test_complete_system.py::TestCompleteSystemIntegration::test_plugin_system_integration")
        return
    
    if args.all:
        success = runner.run_all_tests()
        sys.exit(0 if success else 1)
    
    elif args.suite:
        success = runner.run_specific_test_suite(args.suite)
        sys.exit(0 if success else 1)
    
    elif args.pattern:
        success = runner.run_custom_tests(args.pattern)
        sys.exit(0 if success else 1)
    
    else:
        print("âŒ è¯·æŒ‡å®šè¦è¿è¡Œçš„æµ‹è¯•")
        print("ä½¿ç”¨ --help æŸ¥çœ‹å¯ç”¨é€‰é¡¹")
        sys.exit(1)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è¿è¡Œæµ‹è¯•æ—¶å‘ç”Ÿæœªå¤„ç†çš„å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)