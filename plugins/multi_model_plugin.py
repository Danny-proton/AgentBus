"""
å¤šæ¨¡å‹åè°ƒå™¨æ’ä»¶
Multi-Model Coordinator Plugin

æ­¤æ’ä»¶æä¾›å®Œæ•´çš„å¤šæ¨¡å‹åè°ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- AIæ¨¡å‹çš„æ³¨å†Œå’Œç®¡ç†
- æ™ºèƒ½ä»»åŠ¡åˆ†å‘å’Œåè°ƒ
- å¤šæ¨¡å‹ç»“æœèåˆ
- ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- å®æ—¶ç»Ÿè®¡å’Œç›‘æ§

æ’ä»¶æä¾›çš„å·¥å…·ï¼š
- submit_multi_model_task: æäº¤å¤šæ¨¡å‹ä»»åŠ¡
- register_model: æ³¨å†Œæ–°çš„AIæ¨¡å‹
- get_task_result: è·å–ä»»åŠ¡ç»“æœ
- list_models: åˆ—å‡ºå¯ç”¨æ¨¡å‹
- get_coordinator_stats: è·å–åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯

æ’ä»¶é’©å­ï¼š
- multi_model_task_submitted: ä»»åŠ¡æäº¤æ—¶è§¦å‘
- multi_model_task_completed: ä»»åŠ¡å®Œæˆæ—¶è§¦å‘
- multi_model_task_failed: ä»»åŠ¡å¤±è´¥æ—¶è§¦å‘
- model_registered: æ¨¡å‹æ³¨å†Œæ—¶è§¦å‘
- model_unregistered: æ¨¡å‹æ³¨é”€æ—¶è§¦å‘
"""

import asyncio
import json
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any, Union, Callable, Tuple
from enum import Enum
from dataclasses import asdict

from agentbus.plugins import AgentBusPlugin, PluginContext, PluginTool, PluginHook
from agentbus.services.multi_model_coordinator import (
    MultiModelCoordinator,
    ModelConfig,
    TaskRequest,
    TaskResult,
    TaskType,
    TaskPriority,
    ModelType,
    TaskStatus,
    ModelResult,
)


class MultiModelPlugin(AgentBusPlugin):
    """
    å¤šæ¨¡å‹åè°ƒå™¨æ’ä»¶
    
    åŸºäºå¤šæ¨¡å‹åè°ƒå™¨æœåŠ¡å®ç°çš„å®Œæ•´æ’ä»¶ï¼Œæä¾›ï¼š
    - å®Œæ•´çš„æ¨¡å‹ç®¡ç†å’Œä»»åŠ¡åè°ƒåŠŸèƒ½
    - é€šè¿‡å·¥å…·æ¥å£æš´éœ²æ ¸å¿ƒåŠŸèƒ½
    - äº‹ä»¶é’©å­ç³»ç»Ÿ
    - å®æ—¶çŠ¶æ€ç›‘æ§
    """
    
    def __init__(self, plugin_id: str, context: PluginContext):
        super().__init__(plugin_id, context)
        
        # åˆå§‹åŒ–å¤šæ¨¡å‹åè°ƒå™¨
        self.coordinator = MultiModelCoordinator()
        
        # æ’ä»¶å†…éƒ¨çŠ¶æ€
        self.plugin_stats = {
            'tasks_submitted': 0,
            'tasks_completed': 0,
            'tasks_failed': 0,
            'models_registered': 0,
            'total_processing_time': 0.0,
            'total_cost': 0.0
        }
        
        # ä»»åŠ¡ç›‘æ§
        self.monitored_tasks: Dict[str, float] = {}
        
        self.context.logger.info(f"MultiModelPlugin {plugin_id} initialized")
    
    def get_info(self) -> Dict[str, Any]:
        """
        è¿”å›æ’ä»¶ä¿¡æ¯
        """
        return {
            'id': self.plugin_id,
            'name': 'Multi-Model Coordinator Plugin',
            'version': '1.0.0',
            'description': 'å¤šæ¨¡å‹åè°ƒå™¨æ’ä»¶ï¼Œæä¾›AIæ¨¡å‹çš„ç»Ÿä¸€ç®¡ç†å’Œä»»åŠ¡åè°ƒåŠŸèƒ½',
            'author': 'AgentBus Team',
            'dependencies': [
                'agentbus.services.multi_model_coordinator'
            ],
            'capabilities': [
                'multi_model_coordination',
                'model_management', 
                'task_processing',
                'result_fusion',
                'real_time_monitoring'
            ],
            'config_schema': {
                'default_models': {
                    'type': 'list',
                    'description': 'é»˜è®¤æ³¨å†Œçš„æ¨¡å‹åˆ—è¡¨',
                    'default': []
                },
                'fusion_strategy': {
                    'type': 'string',
                    'description': 'é»˜è®¤èåˆç­–ç•¥',
                    'default': 'best',
                    'options': ['best', 'weighted', 'majority', 'ensemble']
                },
                'max_concurrent_tasks': {
                    'type': 'integer',
                    'description': 'æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°',
                    'default': 10
                },
                'enable_monitoring': {
                    'type': 'boolean',
                    'description': 'å¯ç”¨ä»»åŠ¡ç›‘æ§',
                    'default': True
                }
            }
        }
    
    async def activate(self):
        """
        æ¿€æ´»æ’ä»¶
        """
        # å…ˆè°ƒç”¨çˆ¶ç±»æ–¹æ³•
        await super().activate()
        
        # åˆå§‹åŒ–åè°ƒå™¨
        success = await self.coordinator.initialize()
        if not success:
            raise RuntimeError("Failed to initialize multi-model coordinator")
        
        # æ³¨å†Œæ’ä»¶å·¥å…·
        self._register_tools()
        
        # æ³¨å†Œæ’ä»¶é’©å­
        self._register_hooks()
        
        # æ³¨å†Œæ’ä»¶å‘½ä»¤
        self._register_commands()
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.plugin_stats['models_registered'] = len(self.coordinator.models)
        
        self.context.logger.info(f"MultiModelPlugin {self.plugin_id} activated successfully")
        return True
    
    async def deactivate(self):
        """
        åœç”¨æ’ä»¶
        """
        try:
            # æ¸…ç†ç›‘æ§ä»»åŠ¡
            self.monitored_tasks.clear()
            
            # å…³é—­åè°ƒå™¨
            await self.coordinator.shutdown()
            
            # è°ƒç”¨çˆ¶ç±»æ–¹æ³•
            await super().deactivate()
            
            self.context.logger.info(f"MultiModelPlugin {self.plugin_id} deactivated")
            return True
            
        except Exception as e:
            self.context.logger.error(f"Failed to deactivate plugin {self.plugin_id}: {e}")
            return False
    
    def _register_tools(self):
        """æ³¨å†Œæ’ä»¶å·¥å…·"""
        
        # æäº¤å¤šæ¨¡å‹ä»»åŠ¡
        self.register_tool(
            name='submit_multi_model_task',
            description='æäº¤å¤šæ¨¡å‹ä»»åŠ¡è¿›è¡Œåè°ƒå¤„ç†',
            function=self.submit_multi_model_task
        )
        
        # æ³¨å†Œæ¨¡å‹
        self.register_tool(
            name='register_model',
            description='æ³¨å†Œæ–°çš„AIæ¨¡å‹',
            function=self.register_model_tool
        )
        
        # æ³¨é”€æ¨¡å‹
        self.register_tool(
            name='unregister_model',
            description='æ³¨é”€AIæ¨¡å‹',
            function=self.unregister_model_tool
        )
        
        # è·å–ä»»åŠ¡ç»“æœ
        self.register_tool(
            name='get_task_result',
            description='è·å–ä»»åŠ¡å¤„ç†ç»“æœ',
            function=self.get_task_result_tool
        )
        
        # å–æ¶ˆä»»åŠ¡
        self.register_tool(
            name='cancel_task',
            description='å–æ¶ˆæ­£åœ¨å¤„ç†çš„ä»»åŠ¡',
            function=self.cancel_task_tool
        )
        
        # åˆ—å‡ºæ¨¡å‹
        self.register_tool(
            name='list_models',
            description='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„AIæ¨¡å‹',
            function=self.list_models_tool
        )
        
        # è·å–åè°ƒå™¨ç»Ÿè®¡
        self.register_tool(
            name='get_coordinator_stats',
            description='è·å–å¤šæ¨¡å‹åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯',
            function=self.get_coordinator_stats_tool
        )
        
        # è·å–æ’ä»¶ç»Ÿè®¡
        self.register_tool(
            name='get_plugin_stats',
            description='è·å–æ’ä»¶ç»Ÿè®¡ä¿¡æ¯',
            function=self.get_plugin_stats_tool
        )
        
        # å‡†å¤‡æç¤ºè¯
        self.register_tool(
            name='prepare_prompt',
            description='ä¸ºç‰¹å®šä»»åŠ¡ç±»å‹å‡†å¤‡ä¼˜åŒ–çš„æç¤ºè¯',
            function=self.prepare_prompt_tool
        )
        
        # æ¨¡å‹æ¨è
        self.register_tool(
            name='recommend_models',
            description='ä¸ºç‰¹å®šä»»åŠ¡æ¨èæœ€é€‚åˆçš„æ¨¡å‹',
            function=self.recommend_models_tool
        )
    
    def _register_hooks(self):
        """æ³¨å†Œæ’ä»¶é’©å­"""
        
        # ä»»åŠ¡æäº¤é’©å­
        self.register_hook(
            event='multi_model_task_submitted',
            handler=self.on_task_submitted,
            priority=10
        )
        
        # ä»»åŠ¡å®Œæˆé’©å­
        self.register_hook(
            event='multi_model_task_completed',
            handler=self.on_task_completed,
            priority=10
        )
        
        # ä»»åŠ¡å¤±è´¥é’©å­
        self.register_hook(
            event='multi_model_task_failed',
            handler=self.on_task_failed,
            priority=10
        )
        
        # æ¨¡å‹æ³¨å†Œé’©å­
        self.register_hook(
            event='model_registered',
            handler=self.on_model_registered,
            priority=5
        )
        
        # æ¨¡å‹æ³¨é”€é’©å­
        self.register_hook(
            event='model_unregistered',
            handler=self.on_model_unregistered,
            priority=5
        )
        
        # ç³»ç»Ÿé’©å­
        self.register_hook(
            event='plugin_activated',
            handler=self.on_plugin_activated,
            priority=1
        )
        
        self.register_hook(
            event='plugin_deactivated',
            handler=self.on_plugin_deactivated,
            priority=1
        )
    
    def _register_commands(self):
        """æ³¨å†Œæ’ä»¶å‘½ä»¤"""
        
        self.register_command(
            command='/models',
            handler=self.handle_models_command,
            description='æ˜¾ç¤ºæ‰€æœ‰æ³¨å†Œçš„æ¨¡å‹ä¿¡æ¯'
        )
        
        self.register_command(
            command='/tasks',
            handler=self.handle_tasks_command,
            description='æ˜¾ç¤ºå½“å‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡'
        )
        
        self.register_command(
            command='/stats',
            handler=self.handle_stats_command,
            description='æ˜¾ç¤ºæ’ä»¶å’Œåè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯'
        )
        
        self.register_command(
            command='/health',
            handler=self.handle_health_command,
            description='æ£€æŸ¥å¤šæ¨¡å‹åè°ƒå™¨å¥åº·çŠ¶æ€'
        )
    
    # å·¥å…·å®ç°æ–¹æ³•
    
    async def submit_multi_model_task(self, 
                                    task_type: str,
                                    content: str,
                                    priority: str = "normal",
                                    required_capabilities: List[str] = None,
                                    max_cost: float = None,
                                    max_time: int = None,
                                    preferred_models: List[str] = None,
                                    exclude_models: List[str] = None,
                                    context: Dict[str, Any] = None,
                                    metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æäº¤å¤šæ¨¡å‹ä»»åŠ¡
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹ (text_generation, code_generation, question_answeringç­‰)
            content: ä»»åŠ¡å†…å®¹
            priority: ä»»åŠ¡ä¼˜å…ˆçº§ (low, normal, high, urgent)
            required_capabilities: å¿…éœ€çš„èƒ½åŠ›åˆ—è¡¨
            max_cost: æœ€å¤§æˆæœ¬é™åˆ¶
            max_time: æœ€å¤§å¤„ç†æ—¶é—´(ç§’)
            preferred_models: é¦–é€‰æ¨¡å‹åˆ—è¡¨
            exclude_models: æ’é™¤æ¨¡å‹åˆ—è¡¨
            context: ä»»åŠ¡ä¸Šä¸‹æ–‡
            metadata: ä»»åŠ¡å…ƒæ•°æ®
            
        Returns:
            åŒ…å«ä»»åŠ¡IDå’Œæäº¤çŠ¶æ€çš„å­—å…¸
        """
        try:
            # è½¬æ¢æšä¸¾å€¼
            task_enum = TaskType(task_type)
            priority_enum = TaskPriority(priority)
            
            # åˆ›å»ºä»»åŠ¡è¯·æ±‚
            task_request = TaskRequest(
                task_id=str(uuid.uuid4()),
                task_type=task_enum,
                content=content,
                context=context or {},
                priority=priority_enum,
                required_capabilities=required_capabilities or [],
                max_cost=max_cost,
                max_time=max_time,
                preferred_models=preferred_models or [],
                exclude_models=exclude_models or [],
                metadata=metadata or {}
            )
            
            # æäº¤ä»»åŠ¡
            task_id = await self.coordinator.submit_task(task_request)
            
            # æ›´æ–°æ’ä»¶ç»Ÿè®¡
            self.plugin_stats['tasks_submitted'] += 1
            
            # æ·»åŠ ç›‘æ§
            if self.get_config('enable_monitoring', True):
                self.monitored_tasks[task_id] = datetime.now().timestamp()
            
            # è§¦å‘ä»»åŠ¡æäº¤é’©å­
            await self._trigger_hook('multi_model_task_submitted', {
                'task_id': task_id,
                'task_type': task_type,
                'priority': priority,
                'content_length': len(content)
            })
            
            self.context.logger.info(f"Task submitted successfully: {task_id}")
            
            return {
                'success': True,
                'task_id': task_id,
                'message': f'ä»»åŠ¡å·²æˆåŠŸæäº¤ï¼Œä»»åŠ¡ID: {task_id}',
                'estimated_models': len(self.coordinator.get_available_models(task_enum))
            }
            
        except ValueError as e:
            self.context.logger.error(f"Invalid task parameters: {e}")
            return {
                'success': False,
                'error': f'æ— æ•ˆçš„ä»»åŠ¡å‚æ•°: {str(e)}',
                'task_id': None
            }
        except Exception as e:
            self.context.logger.error(f"Failed to submit task: {e}")
            return {
                'success': False,
                'error': f'ä»»åŠ¡æäº¤å¤±è´¥: {str(e)}',
                'task_id': None
            }
    
    def register_model_tool(self, 
                           model_id: str,
                           model_name: str,
                           model_type: str,
                           provider: str,
                           capabilities: List[str],
                           api_key: str = None,
                           base_url: str = None,
                           max_tokens: int = 4096,
                           temperature: float = 0.7,
                           cost_per_token: float = 0.0,
                           quality_score: float = 1.0,
                           rate_limit: int = 100) -> Dict[str, Any]:
        """
        æ³¨å†ŒAIæ¨¡å‹
        
        Args:
            model_id: æ¨¡å‹å”¯ä¸€æ ‡è¯†ç¬¦
            model_name: æ¨¡å‹æ˜¾ç¤ºåç§°
            model_type: æ¨¡å‹ç±»å‹
            provider: æä¾›è€… (openai, anthropic, localç­‰)
            capabilities: æ¨¡å‹èƒ½åŠ›åˆ—è¡¨
            api_key: APIå¯†é’¥
            base_url: åŸºç¡€URL
            max_tokens: æœ€å¤§tokenæ•°
            temperature: æ¸©åº¦å‚æ•°
            cost_per_token: æ¯tokenæˆæœ¬
            quality_score: è´¨é‡è¯„åˆ†
            rate_limit: é€Ÿç‡é™åˆ¶
            
        Returns:
            æ³¨å†Œç»“æœ
        """
        try:
            # è½¬æ¢æšä¸¾
            model_enum = ModelType(model_type)
            capability_enums = [TaskType(cap) for cap in capabilities]
            
            # åˆ›å»ºæ¨¡å‹é…ç½®
            model_config = ModelConfig(
                model_id=model_id,
                model_name=model_name,
                model_type=model_enum,
                provider=provider,
                api_key=api_key,
                base_url=base_url,
                max_tokens=max_tokens,
                temperature=temperature,
                rate_limit=rate_limit,
                capabilities=capability_enums,
                cost_per_token=cost_per_token,
                quality_score=quality_score
            )
            
            # æ³¨å†Œæ¨¡å‹
            success = self.coordinator.register_model(model_config)
            
            if success:
                self.plugin_stats['models_registered'] += 1
                
                # è§¦å‘æ¨¡å‹æ³¨å†Œé’©å­
                asyncio.create_task(self._trigger_hook('model_registered', {
                    'model_id': model_id,
                    'model_name': model_name,
                    'provider': provider,
                    'capabilities': capabilities
                }))
                
                self.context.logger.info(f"Model registered successfully: {model_id}")
                
                return {
                    'success': True,
                    'model_id': model_id,
                    'message': f'æ¨¡å‹ {model_name} ({model_id}) æ³¨å†ŒæˆåŠŸ'
                }
            else:
                return {
                    'success': False,
                    'model_id': model_id,
                    'error': 'æ¨¡å‹æ³¨å†Œå¤±è´¥'
                }
                
        except ValueError as e:
            self.context.logger.error(f"Invalid model parameters: {e}")
            return {
                'success': False,
                'error': f'æ— æ•ˆçš„æ¨¡å‹å‚æ•°: {str(e)}',
                'model_id': model_id
            }
        except Exception as e:
            self.context.logger.error(f"Failed to register model: {e}")
            return {
                'success': False,
                'error': f'æ¨¡å‹æ³¨å†Œå¤±è´¥: {str(e)}',
                'model_id': model_id
            }
    
    def unregister_model_tool(self, model_id: str) -> Dict[str, Any]:
        """
        æ³¨é”€AIæ¨¡å‹
        
        Args:
            model_id: æ¨¡å‹æ ‡è¯†ç¬¦
            
        Returns:
            æ³¨é”€ç»“æœ
        """
        try:
            success = self.coordinator.unregister_model(model_id)
            
            if success:
                self.plugin_stats['models_registered'] = max(0, self.plugin_stats['models_registered'] - 1)
                
                # è§¦å‘æ¨¡å‹æ³¨é”€é’©å­
                asyncio.create_task(self._trigger_hook('model_unregistered', {
                    'model_id': model_id
                }))
                
                self.context.logger.info(f"Model unregistered: {model_id}")
                
                return {
                    'success': True,
                    'model_id': model_id,
                    'message': f'æ¨¡å‹ {model_id} æ³¨é”€æˆåŠŸ'
                }
            else:
                return {
                    'success': False,
                    'model_id': model_id,
                    'error': 'æ¨¡å‹ä¸å­˜åœ¨æˆ–æ³¨é”€å¤±è´¥'
                }
                
        except Exception as e:
            self.context.logger.error(f"Failed to unregister model: {e}")
            return {
                'success': False,
                'error': f'æ¨¡å‹æ³¨é”€å¤±è´¥: {str(e)}',
                'model_id': model_id
            }
    
    async def get_task_result_tool(self, task_id: str) -> Dict[str, Any]:
        """
        è·å–ä»»åŠ¡ç»“æœ
        
        Args:
            task_id: ä»»åŠ¡æ ‡è¯†ç¬¦
            
        Returns:
            ä»»åŠ¡ç»“æœ
        """
        try:
            result = await self.coordinator.get_task_result(task_id)
            
            if result:
                # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                result_dict = {
                    'success': True,
                    'task_id': task_id,
                    'status': result.status.value,
                    'final_content': result.final_content,
                    'total_time': result.total_time,
                    'total_cost': result.total_cost,
                    'fusion_method': result.fusion_method,
                    'processing_log': result.processing_log,
                    'metadata': result.metadata
                }
                
                # æ·»åŠ æ¨¡å‹ç»“æœè¯¦æƒ…
                if result.model_results:
                    result_dict['model_results'] = [
                        {
                            'model_id': r.model_id,
                            'confidence': r.confidence,
                            'processing_time': r.processing_time,
                            'cost': r.cost,
                            'quality_score': r.quality_score,
                            'error': r.error
                        }
                        for r in result.model_results
                    ]
                
                return result_dict
            else:
                return {
                    'success': False,
                    'task_id': task_id,
                    'error': 'ä»»åŠ¡ä¸å­˜åœ¨æˆ–å°šæœªå®Œæˆ'
                }
                
        except Exception as e:
            self.context.logger.error(f"Failed to get task result: {e}")
            return {
                'success': False,
                'error': f'è·å–ä»»åŠ¡ç»“æœå¤±è´¥: {str(e)}',
                'task_id': task_id
            }
    
    async def cancel_task_tool(self, task_id: str) -> Dict[str, Any]:
        """
        å–æ¶ˆä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡æ ‡è¯†ç¬¦
            
        Returns:
            å–æ¶ˆç»“æœ
        """
        try:
            success = await self.coordinator.cancel_task(task_id)
            
            if success:
                # ä»ç›‘æ§åˆ—è¡¨ä¸­ç§»é™¤
                self.monitored_tasks.pop(task_id, None)
                
                self.context.logger.info(f"Task cancelled: {task_id}")
                
                return {
                    'success': True,
                    'task_id': task_id,
                    'message': f'ä»»åŠ¡ {task_id} å–æ¶ˆæˆåŠŸ'
                }
            else:
                return {
                    'success': False,
                    'task_id': task_id,
                    'error': 'ä»»åŠ¡ä¸å­˜åœ¨æˆ–å–æ¶ˆå¤±è´¥'
                }
                
        except Exception as e:
            self.context.logger.error(f"Failed to cancel task: {e}")
            return {
                'success': False,
                'error': f'ä»»åŠ¡å–æ¶ˆå¤±è´¥: {str(e)}',
                'task_id': task_id
            }
    
    def list_models_tool(self, task_type: str = None) -> Dict[str, Any]:
        """
        åˆ—å‡ºå¯ç”¨æ¨¡å‹
        
        Args:
            task_type: å¯é€‰çš„ä»»åŠ¡ç±»å‹è¿‡æ»¤
            
        Returns:
            æ¨¡å‹åˆ—è¡¨
        """
        try:
            if task_type:
                task_enum = TaskType(task_type)
                models = self.coordinator.get_available_models(task_enum)
            else:
                models = self.coordinator.get_available_models()
            
            model_list = []
            for model in models:
                model_list.append({
                    'model_id': model.model_id,
                    'model_name': model.model_name,
                    'model_type': model.model_type.value,
                    'provider': model.provider,
                    'capabilities': [cap.value for cap in model.capabilities],
                    'max_tokens': model.max_tokens,
                    'temperature': model.temperature,
                    'cost_per_token': model.cost_per_token,
                    'quality_score': model.quality_score,
                    'is_active': model.is_active,
                    'rate_limit': model.rate_limit
                })
            
            return {
                'success': True,
                'models': model_list,
                'total_count': len(model_list),
                'filtered_by': task_type
            }
            
        except ValueError as e:
            return {
                'success': False,
                'error': f'æ— æ•ˆçš„ä»»åŠ¡ç±»å‹: {str(e)}',
                'models': [],
                'total_count': 0
            }
        except Exception as e:
            self.context.logger.error(f"Failed to list models: {e}")
            return {
                'success': False,
                'error': f'è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}',
                'models': [],
                'total_count': 0
            }
    
    async def get_coordinator_stats_tool(self) -> Dict[str, Any]:
        """
        è·å–åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            stats = await self.coordinator.get_coordinator_stats()
            
            # æ·»åŠ ç›‘æ§çš„ä»»åŠ¡ä¿¡æ¯
            monitored_count = len(self.monitored_tasks)
            avg_monitor_time = 0.0
            if self.monitored_tasks:
                current_time = datetime.now().timestamp()
                monitor_times = [current_time - start_time for start_time in self.monitored_tasks.values()]
                avg_monitor_time = sum(monitor_times) / len(monitor_times)
            
            stats['plugin_stats'] = self.plugin_stats
            stats['monitored_tasks'] = monitored_count
            stats['avg_monitor_time'] = avg_monitor_time
            
            return {
                'success': True,
                'stats': stats
            }
            
        except Exception as e:
            self.context.logger.error(f"Failed to get coordinator stats: {e}")
            return {
                'success': False,
                'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'
            }
    
    def get_plugin_stats_tool(self) -> Dict[str, Any]:
        """
        è·å–æ’ä»¶ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            æ’ä»¶ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            return {
                'success': True,
                'plugin_id': self.plugin_id,
                'status': self.status.value,
                'stats': self.plugin_stats.copy(),
                'monitored_tasks': len(self.monitored_tasks),
                'registered_tools': len(self.get_tools()),
                'registered_hooks': sum(len(hooks) for hooks in self.get_hooks().values()),
                'registered_commands': len(self.get_commands())
            }
            
        except Exception as e:
            self.context.logger.error(f"Failed to get plugin stats: {e}")
            return {
                'success': False,
                'error': f'è·å–æ’ä»¶ç»Ÿè®¡å¤±è´¥: {str(e)}'
            }
    
    def prepare_prompt_tool(self, task_type: str, content: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å‡†å¤‡ä¼˜åŒ–çš„æç¤ºè¯
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            content: åŸå§‹å†…å®¹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ä¼˜åŒ–åçš„æç¤ºè¯
        """
        try:
            task_enum = TaskType(task_type)
            
            # åˆ›å»ºä¸´æ—¶ä»»åŠ¡è¯·æ±‚æ¥ä½¿ç”¨å†…ç½®çš„æç¤ºè¯å‡†å¤‡é€»è¾‘
            temp_task = TaskRequest(
                task_id="temp",
                task_type=task_enum,
                content=content,
                context=context or {}
            )
            
            # ä½¿ç”¨åè°ƒå™¨çš„æ–¹æ³•å‡†å¤‡æç¤ºè¯
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹Ÿä¸€ä¸ªæ¨¡å‹é…ç½®
            from agentbus.services.multi_model_coordinator import ModelConfig, ModelType
            temp_model = ModelConfig(
                model_id="temp",
                model_name="Temp",
                model_type=ModelType.TEXT_GENERATION,
                provider="local"
            )
            
            prepared_prompt = self.coordinator._prepare_prompt(temp_task, temp_model)
            
            return {
                'success': True,
                'original_content': content,
                'prepared_prompt': prepared_prompt,
                'task_type': task_type,
                'optimization_applied': prepared_prompt != content
            }
            
        except Exception as e:
            self.context.logger.error(f"Failed to prepare prompt: {e}")
            return {
                'success': False,
                'error': f'æç¤ºè¯å‡†å¤‡å¤±è´¥: {str(e)}'
            }
    
    def recommend_models_tool(self, task_type: str, max_models: int = 5) -> Dict[str, Any]:
        """
        ä¸ºç‰¹å®šä»»åŠ¡æ¨èæ¨¡å‹
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            max_models: æœ€å¤§æ¨èæ•°é‡
            
        Returns:
            æ¨èæ¨¡å‹åˆ—è¡¨
        """
        try:
            task_enum = TaskType(task_type)
            available_models = self.coordinator.get_available_models(task_enum)
            
            # æŒ‰è´¨é‡å’Œæˆæœ¬æ’åº
            recommended = sorted(
                available_models,
                key=lambda m: (m.quality_score, -m.cost_per_token),
                reverse=True
            )[:max_models]
            
            recommendations = []
            for model in recommended:
                recommendations.append({
                    'model_id': model.model_id,
                    'model_name': model.model_name,
                    'provider': model.provider,
                    'quality_score': model.quality_score,
                    'cost_per_token': model.cost_per_token,
                    'max_tokens': model.max_tokens,
                    'estimated_cost': model.cost_per_token * 1000,  # ä¼°ç®—1000 tokençš„æˆæœ¬
                    'capabilities': [cap.value for cap in model.capabilities]
                })
            
            return {
                'success': True,
                'task_type': task_type,
                'recommended_models': recommendations,
                'total_available': len(available_models),
                'recommendation_count': len(recommendations)
            }
            
        except ValueError as e:
            return {
                'success': False,
                'error': f'æ— æ•ˆçš„ä»»åŠ¡ç±»å‹: {str(e)}',
                'recommended_models': []
            }
        except Exception as e:
            self.context.logger.error(f"Failed to recommend models: {e}")
            return {
                'success': False,
                'error': f'æ¨¡å‹æ¨èå¤±è´¥: {str(e)}',
                'recommended_models': []
            }
    
    # é’©å­å¤„ç†æ–¹æ³•
    
    async def on_task_submitted(self, task_data: Dict[str, Any]):
        """ä»»åŠ¡æäº¤é’©å­å¤„ç†"""
        self.context.logger.debug(f"Task submitted hook: {task_data.get('task_id')}")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘ï¼Œæ¯”å¦‚ï¼š
        # - è®°å½•æ—¥å¿—
        # - å‘é€é€šçŸ¥
        # - æ›´æ–°ç›‘æ§æŒ‡æ ‡
        pass
    
    async def on_task_completed(self, task_data: Dict[str, Any]):
        """ä»»åŠ¡å®Œæˆé’©å­å¤„ç†"""
        task_id = task_data.get('task_id')
        self.context.logger.debug(f"Task completed hook: {task_id}")
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.plugin_stats['tasks_completed'] += 1
        
        # ä»ç›‘æ§åˆ—è¡¨ä¸­ç§»é™¤
        self.monitored_tasks.pop(task_id, None)
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘
        pass
    
    async def on_task_failed(self, task_data: Dict[str, Any]):
        """ä»»åŠ¡å¤±è´¥é’©å­å¤„ç†"""
        task_id = task_data.get('task_id')
        self.context.logger.debug(f"Task failed hook: {task_id}")
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.plugin_stats['tasks_failed'] += 1
        
        # ä»ç›‘æ§åˆ—è¡¨ä¸­ç§»é™¤
        self.monitored_tasks.pop(task_id, None)
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘ï¼Œæ¯”å¦‚å‘é€å‘Šè­¦
        pass
    
    async def on_model_registered(self, model_data: Dict[str, Any]):
        """æ¨¡å‹æ³¨å†Œé’©å­å¤„ç†"""
        self.context.logger.debug(f"Model registered hook: {model_data.get('model_id')}")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘
        pass
    
    async def on_model_unregistered(self, model_data: Dict[str, Any]):
        """æ¨¡å‹æ³¨é”€é’©å­å¤„ç†"""
        self.context.logger.debug(f"Model unregistered hook: {model_data.get('model_id')}")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘
        pass
    
    async def on_plugin_activated(self, plugin_data: Dict[str, Any]):
        """æ’ä»¶æ¿€æ´»é’©å­å¤„ç†"""
        self.context.logger.info("MultiModelPlugin activated")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘
        pass
    
    async def on_plugin_deactivated(self, plugin_data: Dict[str, Any]):
        """æ’ä»¶åœç”¨é’©å­å¤„ç†"""
        self.context.logger.info("MultiModelPlugin deactivated")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰é€»è¾‘
        pass
    
    # å‘½ä»¤å¤„ç†æ–¹æ³•
    
    async def handle_models_command(self, args: str) -> str:
        """å¤„ç†æ¨¡å‹åˆ—è¡¨å‘½ä»¤"""
        try:
            task_type = args.strip() if args else None
            
            result = self.list_models_tool(task_type)
            
            if result['success']:
                models_info = []
                for model in result['models']:
                    status = "ğŸŸ¢" if model['is_active'] else "ğŸ”´"
                    models_info.append(
                        f"{status} {model['model_name']} ({model['model_id']}) - {model['provider']}"
                    )
                
                info_text = f"ğŸ“Š æ¨¡å‹åˆ—è¡¨ (æ€»è®¡: {result['total_count']})\n"
                if task_type:
                    info_text += f"è¿‡æ»¤æ¡ä»¶: {task_type}\n"
                info_text += "\n" + "\n".join(models_info)
                
                return info_text
            else:
                return f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {result['error']}"
                
        except Exception as e:
            return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    async def handle_tasks_command(self, args: str) -> str:
        """å¤„ç†ä»»åŠ¡åˆ—è¡¨å‘½ä»¤"""
        try:
            # è·å–åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯
            stats_result = await self.get_coordinator_stats_tool()
            
            if stats_result['success']:
                stats = stats_result['stats']
                
                tasks_info = f"ğŸ“‹ ä»»åŠ¡çŠ¶æ€\n"
                tasks_info += f"æ´»è·ƒä»»åŠ¡: {stats['active_tasks']}\n"
                tasks_info += f"æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}\n"
                tasks_info += f"æˆåŠŸç‡: {stats['success_rate']:.1%}\n"
                tasks_info += f"ç›‘æ§ä»»åŠ¡: {stats['monitored_tasks']}\n"
                
                if stats['monitored_tasks'] > 0:
                    tasks_info += f"å¹³å‡ç›‘æ§æ—¶é—´: {stats['avg_monitor_time']:.1f}ç§’\n"
                
                return tasks_info
            else:
                return f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {stats_result['error']}"
                
        except Exception as e:
            return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    async def handle_stats_command(self, args: str) -> str:
        """å¤„ç†ç»Ÿè®¡ä¿¡æ¯å‘½ä»¤"""
        try:
            plugin_stats = self.get_plugin_stats_tool()
            coordinator_stats = await self.get_coordinator_stats_tool()
            
            if plugin_stats['success'] and coordinator_stats['success']:
                stats = plugin_stats['stats']
                coord_stats = coordinator_stats['stats']
                
                stats_info = f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯\n\n"
                stats_info += f"æ’ä»¶ç»Ÿè®¡:\n"
                stats_info += f"  æäº¤ä»»åŠ¡: {stats['tasks_submitted']}\n"
                stats_info += f"  å®Œæˆä»»åŠ¡: {stats['tasks_completed']}\n"
                stats_info += f"  å¤±è´¥ä»»åŠ¡: {stats['tasks_failed']}\n"
                stats_info += f"  æ³¨å†Œæ¨¡å‹: {stats['models_registered']}\n"
                stats_info += f"  æ€»å¤„ç†æ—¶é—´: {stats['total_processing_time']:.1f}ç§’\n"
                stats_info += f"  æ€»æˆæœ¬: ${stats['total_cost']:.6f}\n\n"
                
                stats_info += f"åè°ƒå™¨ç»Ÿè®¡:\n"
                stats_info += f"  æ´»è·ƒä»»åŠ¡: {coord_stats['active_tasks']}\n"
                stats_info += f"  å¹³å‡å¤„ç†æ—¶é—´: {coord_stats['avg_processing_time']:.2f}ç§’\n"
                stats_info += f"  å¹³å‡æˆæœ¬: ${coord_stats['avg_cost']:.6f}\n"
                stats_info += f"  æ´»è·ƒæ¨¡å‹: {coord_stats['active_models']}\n"
                
                return stats_info
            else:
                return f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥"
                
        except Exception as e:
            return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    async def handle_health_command(self, args: str) -> str:
        """å¤„ç†å¥åº·æ£€æŸ¥å‘½ä»¤"""
        try:
            # æ£€æŸ¥åè°ƒå™¨çŠ¶æ€
            coordinator_stats = await self.get_coordinator_stats_tool()
            
            if coordinator_stats['success']:
                stats = coordinator_stats['stats']
                
                # è¯„ä¼°å¥åº·çŠ¶æ€
                health_score = 100
                issues = []
                
                if stats['active_tasks'] > 20:
                    health_score -= 20
                    issues.append("æ´»è·ƒä»»åŠ¡è¿‡å¤š")
                
                if stats['success_rate'] < 0.8:
                    health_score -= 30
                    issues.append("ä»»åŠ¡æˆåŠŸç‡åä½")
                
                if stats['registered_models'] == 0:
                    health_score -= 50
                    issues.append("æ²¡æœ‰æ³¨å†Œæ¨¡å‹")
                
                if health_score >= 80:
                    status = "ğŸŸ¢ å¥åº·"
                elif health_score >= 60:
                    status = "ğŸŸ¡ è­¦å‘Š"
                else:
                    status = "ğŸ”´ ä¸å¥åº·"
                
                health_info = f"ğŸ’Š å¥åº·æ£€æŸ¥\n"
                health_info += f"çŠ¶æ€: {status} (åˆ†æ•°: {health_score})\n"
                health_info += f"åè°ƒå™¨çŠ¶æ€: {'æ­£å¸¸' if self.coordinator.is_running else 'å¼‚å¸¸'}\n"
                health_info += f"æ³¨å†Œæ¨¡å‹: {stats['registered_models']}\n"
                health_info += f"æ´»è·ƒæ¨¡å‹: {stats['active_models']}\n"
                
                if issues:
                    health_info += f"\né—®é¢˜:\n" + "\n".join(f"  âš ï¸ {issue}" for issue in issues)
                
                return health_info
            else:
                return f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {coordinator_stats['error']}"
                
        except Exception as e:
            return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    async def _trigger_hook(self, event: str, data: Dict[str, Any]):
        """è§¦å‘é’©å­"""
        try:
            hooks = self.get_hooks().get(event, [])
            for hook in hooks:
                if hook.async_func:
                    await hook.handler(data)
                else:
                    hook.handler(data)
        except Exception as e:
            self.context.logger.error(f"Failed to trigger hook {event}: {e}")